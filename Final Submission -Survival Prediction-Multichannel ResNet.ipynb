{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321b3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 20:23:07.085353: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 20:23:07.149165: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 20:23:07.150154: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 20:23:08.821623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchinfo in ./.local/lib/python3.9/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "#from PIL import Image\n",
    "import PIL.Image as Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "#from  import keras.layers.Add\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde36c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarker_completeList = ['CD11c','CD14',\n",
    " 'CD163',\n",
    " 'CD20',\n",
    " 'CD3',\n",
    " 'CD31',\n",
    " 'CD38',\n",
    " 'CD4',\n",
    " 'CD45',\n",
    " 'CD45RB',\n",
    " 'CD45RO',\n",
    " 'CD56',\n",
    " 'CD57',\n",
    " 'CD68',\n",
    " 'CD69',\n",
    " 'CD8',\n",
    " 'CK17',\n",
    " 'ChyTr',\n",
    " 'Collagen1',\n",
    " 'ECAD',\n",
    " 'FAP',\n",
    " 'FOXP3',\n",
    " 'Fibronectin',\n",
    " 'GLUT1',\n",
    " 'H3K27me3',\n",
    " 'H3K9ac',\n",
    " 'HLA1',\n",
    " 'HLADR',\n",
    " 'IDO',\n",
    " 'Ki67',\n",
    " 'LAG3',\n",
    " 'PD1',\n",
    " 'PDL1',\n",
    " 'SMA',\n",
    " 'TBET',\n",
    " 'TCF1',\n",
    " 'TIM3',\n",
    " 'Vim']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e643e",
   "metadata": {},
   "source": [
    "Some of the biomarkers are functional biomarkers which are not very informative on the cell type. So, we decided to exclude them from the model. We ended up 20 biomarkers listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1537ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markerNum = len(biomarkerList)\n",
    "# biomarker_toKeep = pd.read_excel('Markers to Use.xlsx')\n",
    "# values = biomarker_toKeep['Marker'].values.tolist()\n",
    "\n",
    "biomarker_toKeep = ['Calprotectin',\n",
    " 'CD11c',\n",
    " 'CD14',\n",
    " 'CD163',\n",
    " 'CD20',\n",
    " 'CD3',\n",
    " 'CD31',\n",
    " 'CD4',\n",
    " 'CD45',\n",
    " 'CD56',\n",
    " 'CD68',\n",
    " 'CD8',\n",
    " 'ChyTr',\n",
    " 'CK17',\n",
    " 'FAP',\n",
    " 'FOXP3',\n",
    " 'HLADR',\n",
    " 'PD1',\n",
    " 'PDL1',\n",
    " 'SMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf0334",
   "metadata": {},
   "source": [
    "### Metadata have the patient IDs, tumor location of the corresponding images, and response to therapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40bb1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fov</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Localization</th>\n",
       "      <th>iRECIST_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TONIC_TMA2_R4C1</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TONIC_TMA2_R4C2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TONIC_TMA2_R4C3</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TONIC_TMA2_R9C6</td>\n",
       "      <td>5</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TONIC_TMA2_R10C1</td>\n",
       "      <td>5</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TONIC_TMA20_R6C5</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>TONIC_TMA20_R6C6</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>TONIC_TMA20_R8C4</td>\n",
       "      <td>117</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>TONIC_TMA20_R8C5</td>\n",
       "      <td>117</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>TONIC_TMA20_R8C6</td>\n",
       "      <td>117</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fov  Patient_ID Localization iRECIST_response\n",
       "0     TONIC_TMA2_R4C1           2        Other   non-responders\n",
       "1     TONIC_TMA2_R4C2           2        Other   non-responders\n",
       "2     TONIC_TMA2_R4C3           2        Other   non-responders\n",
       "3     TONIC_TMA2_R9C6           5         Skin       responders\n",
       "4    TONIC_TMA2_R10C1           5         Skin       responders\n",
       "..                ...         ...          ...              ...\n",
       "162  TONIC_TMA20_R6C5         116    Lymphnode   non-responders\n",
       "163  TONIC_TMA20_R6C6         116    Lymphnode   non-responders\n",
       "164  TONIC_TMA20_R8C4         117         Skin       responders\n",
       "165  TONIC_TMA20_R8C5         117         Skin       responders\n",
       "166  TONIC_TMA20_R8C6         117         Skin       responders\n",
       "\n",
       "[167 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metadata = pd.read_excel('/oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/simplified_metadata.xlsx')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fee9c2",
   "metadata": {},
   "source": [
    "### creating label column based on patients response to therapy. \n",
    " 0 = non-responder\n",
    " 1 = responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c6398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fov</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Localization</th>\n",
       "      <th>iRECIST_response</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TONIC_TMA2_R4C1</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TONIC_TMA2_R4C2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TONIC_TMA2_R4C3</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TONIC_TMA2_R9C6</td>\n",
       "      <td>5</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TONIC_TMA2_R10C1</td>\n",
       "      <td>5</td>\n",
       "      <td>Skin</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fov  Patient_ID Localization iRECIST_response  y\n",
       "0   TONIC_TMA2_R4C1           2        Other   non-responders  0\n",
       "1   TONIC_TMA2_R4C2           2        Other   non-responders  0\n",
       "2   TONIC_TMA2_R4C3           2        Other   non-responders  0\n",
       "3   TONIC_TMA2_R9C6           5         Skin       responders  1\n",
       "4  TONIC_TMA2_R10C1           5         Skin       responders  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metadata['y'] = np.where(metadata['iRECIST_response']== 'responders', 1, 0)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e36e07",
   "metadata": {},
   "source": [
    "Tumor localization can be different for each patient based on where the cancer metastasized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "81043717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Breast', 'Liver', 'Lung', 'Lymphnode', 'Other', 'Skin', 'Thoracal'}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(metadata['Localization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "01166f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fov</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Localization</th>\n",
       "      <th>iRECIST_response</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TONIC_TMA21_R7C1</td>\n",
       "      <td>4</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TONIC_TMA21_R6C5</td>\n",
       "      <td>4</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TONIC_TMA21_R6C6</td>\n",
       "      <td>4</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TONIC_TMA10_R1C5</td>\n",
       "      <td>56</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>responders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TONIC_TMA10_R5C2</td>\n",
       "      <td>57</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>TONIC_TMA20_R1C6</td>\n",
       "      <td>114</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>TONIC_TMA20_R7C1</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>TONIC_TMA20_R7C2</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TONIC_TMA20_R6C5</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>TONIC_TMA20_R6C6</td>\n",
       "      <td>116</td>\n",
       "      <td>Lymphnode</td>\n",
       "      <td>non-responders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fov  Patient_ID Localization iRECIST_response  y\n",
       "5    TONIC_TMA21_R7C1           4    Lymphnode       responders  1\n",
       "6    TONIC_TMA21_R6C5           4    Lymphnode       responders  1\n",
       "7    TONIC_TMA21_R6C6           4    Lymphnode       responders  1\n",
       "8    TONIC_TMA10_R1C5          56    Lymphnode       responders  1\n",
       "9    TONIC_TMA10_R5C2          57    Lymphnode   non-responders  0\n",
       "..                ...         ...          ...              ... ..\n",
       "159  TONIC_TMA20_R1C6         114    Lymphnode   non-responders  0\n",
       "160  TONIC_TMA20_R7C1         116    Lymphnode   non-responders  0\n",
       "161  TONIC_TMA20_R7C2         116    Lymphnode   non-responders  0\n",
       "162  TONIC_TMA20_R6C5         116    Lymphnode   non-responders  0\n",
       "163  TONIC_TMA20_R6C6         116    Lymphnode   non-responders  0\n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[metadata['Localization'] == 'Lymphnode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6522fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aFileNames = metadata.loc[metadata['Localization'] == 'Lymphnode']['fov'].values.tolist()\n",
    "\n",
    "aFileNamesLabels = metadata.loc[metadata['Localization'] == 'Lymphnode']['y'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc1b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "aFileNames_train, aFileNames_test, aFileNamesLabels_train, aFileNamesLabels_test = train_test_split(aFileNames, aFileNamesLabels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8f4d9",
   "metadata": {},
   "source": [
    "66 training sample, 17 test, equal distribution of responders/non-responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72bbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_models = {18: torchvision.models.resnet18,\n",
    "                 34: torchvision.models.resnet34,\n",
    "                 50: torchvision.models.resnet50,\n",
    "                 101: torchvision.models.resnet101,\n",
    "                 152: torchvision.models.resnet152}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726fe941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet_multichannel(nn.Module):\n",
    "    def __init__(self, pretrained=True, encoder_depth=34, num_in_channels=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        if encoder_depth not in [18, 34, 50, 101, 152]:\n",
    "            raise ValueError(f\"Encoder depth {encoder_depth} specified does not match any existing Resnet models\")\n",
    "            \n",
    "        model = resnet_models[encoder_depth](pretrained)\n",
    "        \n",
    "        print(model.conv1)\n",
    "        \n",
    "        ##For reference: layers to use (in order):\n",
    "        # conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc\n",
    "        \n",
    "        # This increases the number of in channels for our network\n",
    "        self.conv1 = self.increase_channels(model.conv1, num_in_channels)\n",
    "        \n",
    "        self.bn1 = model.bn1\n",
    "        self.relu = model.relu\n",
    "        self.maxpool = model.maxpool\n",
    "        self.layer1 = model.layer1\n",
    "        self.layer2 = model.layer2\n",
    "        self.layer3 = model.layer3\n",
    "        self.layer4 = model.layer4\n",
    "        self.avgpool = model.avgpool\n",
    "        \n",
    "        self.fc = model.fc\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def increase_channels(self, m, num_channels=None, copy_weights=0):\n",
    "        \"\"\"\n",
    "        takes as input a Conv2d layer and returns the a Conv2d layer with `num_channels` input channels\n",
    "        and all the previous weights copied into the new layer.\n",
    "        \"\"\"\n",
    "        # number of input channels the new module should have\n",
    "        new_in_channels = num_channels if num_channels is not None else m.in_channels + 1\n",
    "        \n",
    "        print(m.in_channels)\n",
    "        print(new_in_channels)\n",
    "       \n",
    "        \n",
    "        bias = False if m.bias is None else True\n",
    "        \n",
    "        # Creating new Conv2d layer\n",
    "        new_m = nn.Conv2d(in_channels=new_in_channels, \n",
    "                          out_channels=m.out_channels, \n",
    "                          kernel_size=m.kernel_size, \n",
    "                          stride=m.stride, \n",
    "                          padding=m.padding,\n",
    "                          bias=bias)\n",
    "        \n",
    "        # Copying the weights from the old to the new layer\n",
    "        new_m.weight.data[:, :m.in_channels, :, :] = m.weight.clone()\n",
    "        \n",
    "        #Copying the weights of the `copy_weights` channel of the old layer to the extra channels of the new layer\n",
    "        print(new_in_channels - m.in_channels)\n",
    "        for i in range(new_in_channels - m.in_channels):\n",
    "            channel = m.in_channels + i\n",
    "            new_m.weight.data[:, channel:channel+1, :, :] = m.weight[:, copy_weights:copy_weights+1, : :].clone()\n",
    "        new_m.weight = nn.Parameter(new_m.weight)\n",
    "\n",
    "        return new_m\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530aa484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arch(encoder_depth, num_in_channels):\n",
    "    \"\"\"\n",
    "    Returns just an architecture which can then be called in the usual way.\n",
    "    For example:\n",
    "    resnet34_4_channel = get_arch(34, 4)\n",
    "    model = resnet34_4_channel(True)\n",
    "    \"\"\"\n",
    "    return partial(Resnet_multichannel, encoder_depth=encoder_depth, num_in_channels=num_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee2a513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markerNum = len(biomarker_toKeep)\n",
    "markerNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f56c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsimon/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/bgsimon/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "3\n",
      "20\n",
      "17\n",
      "Total input channels :  20\n"
     ]
    }
   ],
   "source": [
    "resnet50_mchannel = get_arch(50, markerNum)\n",
    "#model = resnet50_mchannel(True) \n",
    "\n",
    "model = resnet50_mchannel(True) \n",
    "\n",
    "print(\"Total input channels : \", model.conv1.in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "144af5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            #print(param)\n",
    "            param.requires_grad = False\n",
    "            \n",
    "feature_extract = True\n",
    "set_parameter_requires_grad(model, feature_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c930a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "47ba8964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "Resnet_multichannel                      --\n",
      "â”œâ”€Conv2d: 1-1                            (62,720)\n",
      "â”œâ”€BatchNorm2d: 1-2                       (128)\n",
      "â”œâ”€ReLU: 1-3                              --\n",
      "â”œâ”€MaxPool2d: 1-4                         --\n",
      "â”œâ”€Sequential: 1-5                        --\n",
      "â”‚    â””â”€Bottleneck: 2-1                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-1                  (4,096)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-2             (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-3                  (36,864)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-4             (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-5                  (16,384)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-6             (512)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-7                    --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-8              (16,896)\n",
      "â”‚    â””â”€Bottleneck: 2-2                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-9                  (16,384)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-10            (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-11                 (36,864)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-12            (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-13                 (16,384)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-14            (512)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-15                   --\n",
      "â”‚    â””â”€Bottleneck: 2-3                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-16                 (16,384)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-17            (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-18                 (36,864)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-19            (128)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-20                 (16,384)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-21            (512)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-22                   --\n",
      "â”œâ”€Sequential: 1-6                        --\n",
      "â”‚    â””â”€Bottleneck: 2-4                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-23                 (32,768)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-24            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-25                 (147,456)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-26            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-27                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-28            (1,024)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-29                   --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-30             (132,096)\n",
      "â”‚    â””â”€Bottleneck: 2-5                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-31                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-32            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-33                 (147,456)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-34            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-35                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-36            (1,024)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-37                   --\n",
      "â”‚    â””â”€Bottleneck: 2-6                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-38                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-39            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-40                 (147,456)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-41            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-42                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-43            (1,024)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-44                   --\n",
      "â”‚    â””â”€Bottleneck: 2-7                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-45                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-46            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-47                 (147,456)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-48            (256)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-49                 (65,536)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-50            (1,024)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-51                   --\n",
      "â”œâ”€Sequential: 1-7                        --\n",
      "â”‚    â””â”€Bottleneck: 2-8                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-52                 (131,072)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-53            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-54                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-55            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-56                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-57            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-58                   --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-59             (526,336)\n",
      "â”‚    â””â”€Bottleneck: 2-9                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-60                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-61            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-62                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-63            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-64                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-65            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-66                   --\n",
      "â”‚    â””â”€Bottleneck: 2-10                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-67                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-68            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-69                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-70            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-71                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-72            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-73                   --\n",
      "â”‚    â””â”€Bottleneck: 2-11                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-74                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-75            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-76                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-77            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-78                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-79            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-80                   --\n",
      "â”‚    â””â”€Bottleneck: 2-12                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-81                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-82            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-83                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-84            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-85                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-86            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-87                   --\n",
      "â”‚    â””â”€Bottleneck: 2-13                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-88                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-89            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-90                 (589,824)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-91            (512)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-92                 (262,144)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-93            (2,048)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-94                   --\n",
      "â”œâ”€Sequential: 1-8                        --\n",
      "â”‚    â””â”€Bottleneck: 2-14                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-95                 (524,288)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-96            (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-97                 (2,359,296)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-98            (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-99                 (1,048,576)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-100           (4,096)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-101                  --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-102            (2,101,248)\n",
      "â”‚    â””â”€Bottleneck: 2-15                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-103                (1,048,576)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-104           (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-105                (2,359,296)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-106           (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-107                (1,048,576)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-108           (4,096)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-109                  --\n",
      "â”‚    â””â”€Bottleneck: 2-16                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-110                (1,048,576)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-111           (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-112                (2,359,296)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-113           (1,024)\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-114                (1,048,576)\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-115           (4,096)\n",
      "â”‚    â”‚    â””â”€ReLU: 3-116                  --\n",
      "â”œâ”€AdaptiveAvgPool2d: 1-9                 --\n",
      "â”œâ”€Linear: 1-10                           4,098\n",
      "=================================================================\n",
      "Total params: 23,565,442\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,561,344\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5b38f",
   "metadata": {},
   "source": [
    "Total params: 23,565,442\n",
    "\n",
    "Trainable params: 4,098\n",
    "\n",
    "Non-trainable params: 23,561,344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4beb472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = model.to(device)\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc2c59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25): #optimizer,\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    labels_lst = []\n",
    "    preds_lst = []\n",
    "    weights = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if epoch == num_epochs - 1:\n",
    "                    labels_lst.append(labels)\n",
    "                    preds_lst.append(preds)\n",
    "                    \n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            print(\"weights\")\n",
    "            print(model.state_dict()['fc.weight'][0])\n",
    "            weights.append(model.state_dict()['fc.weight'][0])\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(\"better than best_acc\")\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                \n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, val_loss_history, time_elapsed, labels_lst, preds_lst, weights\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5510a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'pred_progress_v_0'\n",
    "num_classes = 2\n",
    "dir_experiment= '/oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/'\n",
    "dir1 = dir_experiment+experiment_name\n",
    "dir2 = dir_experiment+experiment_name+\"/train/\"\n",
    "dir3 = dir_experiment+experiment_name+\"/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "20bdf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "dir1 = dir_experiment+experiment_name\n",
    "dir2 = dir_experiment+experiment_name+\"/train/\"\n",
    "dir3 = dir_experiment+experiment_name+\"/val/\"\n",
    "\n",
    "if not os.path.exists(dir_experiment):\n",
    "    \n",
    "    os.mkdir(dir_experiment)\n",
    "\n",
    "if not os.path.exists(dir1):\n",
    "    os.mkdir(dir1)\n",
    "if not os.path.exists(dir2):\n",
    "    os.mkdir(dir2)\n",
    "if not os.path.exists(dir3):\n",
    "    os.mkdir(dir3)\n",
    "\n",
    "    \n",
    "\n",
    "uniqueLabels = [0,1]\n",
    "\n",
    "for j in range(len(uniqueLabels)):\n",
    "    n_dir = dir2+str(uniqueLabels[j])+'/'\n",
    "    if not os.path.exists(n_dir):\n",
    "        os.mkdir(n_dir)\n",
    "for j in range(len(uniqueLabels)):\n",
    "    n_dir = dir3+str(uniqueLabels[j])+'/'\n",
    "    if not os.path.exists(n_dir):\n",
    "        os.mkdir(n_dir)\n",
    "\n",
    "    \n",
    "for i in range(len(aFileNames_train)):\n",
    "    file = dir2+str(aFileNamesLabels_train[i])+'/'+aFileNames_train[i]+'.tiff'\n",
    "    open(file, 'a').close()\n",
    "\n",
    "for i in range(len(aFileNames_test)):\n",
    "    file = dir3+str(aFileNamesLabels_test[i])+'/'+aFileNames_test[i]+'.tiff'\n",
    "    open(file, 'a').close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e2321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "RAW_Image_Source_Folder = '/oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/pred_progress_v_0_images/'\n",
    "\n",
    "def my_tiff_loader(filename):    \n",
    "    \n",
    "    head_tail = os.path.split(filename)\n",
    "    filenameWithTiff = head_tail[-1]\n",
    "    \n",
    "    \n",
    "    fileNameToBeUsed = filenameWithTiff[0:-(len('.tiff'))]    \n",
    "        \n",
    "    folder_path = RAW_Image_Source_Folder+fileNameToBeUsed+'/'\n",
    "    \n",
    "    cdir = !ls $folder_path\n",
    "\n",
    "    for n in cdir:\n",
    "        if n[-5:] == '.tiff':\n",
    "            newn = n.replace(\".tiff\", \".tif\" )\n",
    "            os.rename(folder_path+n, folder_path+newn)\n",
    "\n",
    "    i=0\n",
    "    cdir = !ls $folder_path\n",
    "    for my_tif in cdir:\n",
    "\n",
    "        biomarkerName = my_tif[0:-(len('.tif'))]\n",
    "        if biomarkerName in biomarker_toKeep:\n",
    "        \n",
    "            image_dir = folder_path+my_tif\n",
    "\n",
    "            if i==0:\n",
    "                im = Image.open(image_dir)\n",
    "                im = im.resize([224,224])\n",
    "                image = to_tensor(im)\n",
    "            else:\n",
    "                im = Image.open(image_dir) \n",
    "                im = im.resize([224,224])\n",
    "                next_channel = to_tensor(im)\n",
    "                image = torch.cat((image,next_channel),0)\n",
    "            i += 1\n",
    "\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b079354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<torch.utils.data.dataloader.DataLoader object at 0x2b6ed8dad6d0>, <torch.utils.data.dataloader.DataLoader object at 0x2b6ed8dad8e0>])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(dir1, x),loader=my_tiff_loader) for x in ['train','val']} # ,val \n",
    "\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=1, shuffle=True, num_workers=0) for x in ['train','val']} #val\n",
    "\n",
    "dataloaders_dict.values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60d5bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 66\n",
       "     Root location: /oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/pred_progress_v_0/train,\n",
       " 'val': Dataset ImageFolder\n",
       "     Number of datapoints: 17\n",
       "     Root location: /oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/pred_progress_v_0/val}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f12808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([Dataset ImageFolder\n",
       "    Number of datapoints: 66\n",
       "    Root location: /oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/pred_progress_v_0/train, Dataset ImageFolder\n",
       "    Number of datapoints: 17\n",
       "    Root location: /oak/stanford/groups/ccurtis2/users/bgsimon/CS230_CourseProject/pred_progress_v_0/val])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d90bc81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.9111 Acc: 0.6364\n",
      "weights\n",
      "tensor([-0.0131,  0.0204, -0.0174,  ..., -0.0058,  0.0029,  0.0112])\n",
      "val Loss: 1.5050 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0131,  0.0204, -0.0174,  ..., -0.0058,  0.0029,  0.0112])\n",
      "better than best_acc\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.9977 Acc: 0.7121\n",
      "weights\n",
      "tensor([-1.5105e-02,  1.9141e-02, -1.8671e-02,  ..., -8.5395e-03,\n",
      "        -4.6901e-05,  9.0248e-03])\n",
      "val Loss: 0.6728 Acc: 0.5294\n",
      "weights\n",
      "tensor([-1.5105e-02,  1.9141e-02, -1.8671e-02,  ..., -8.5395e-03,\n",
      "        -4.6901e-05,  9.0248e-03])\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.3216 Acc: 0.5606\n",
      "weights\n",
      "tensor([-0.0151,  0.0202, -0.0177,  ..., -0.0090,  0.0014,  0.0095])\n",
      "val Loss: 0.6972 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0151,  0.0202, -0.0177,  ..., -0.0090,  0.0014,  0.0095])\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.0301 Acc: 0.6364\n",
      "weights\n",
      "tensor([-0.0171,  0.0188, -0.0192,  ..., -0.0110, -0.0009,  0.0080])\n",
      "val Loss: 1.8819 Acc: 0.2941\n",
      "weights\n",
      "tensor([-0.0171,  0.0188, -0.0192,  ..., -0.0110, -0.0009,  0.0080])\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.8853 Acc: 0.6061\n",
      "weights\n",
      "tensor([-1.7938e-02,  2.1064e-02, -1.6635e-02,  ..., -1.0734e-02,\n",
      "         5.1285e-05,  7.3544e-03])\n",
      "val Loss: 1.1813 Acc: 0.2941\n",
      "weights\n",
      "tensor([-1.7938e-02,  2.1064e-02, -1.6635e-02,  ..., -1.0734e-02,\n",
      "         5.1285e-05,  7.3544e-03])\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.6667\n",
      "weights\n",
      "tensor([-0.0162,  0.0269, -0.0113,  ..., -0.0091,  0.0026,  0.0098])\n",
      "val Loss: 1.5440 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0162,  0.0269, -0.0113,  ..., -0.0091,  0.0026,  0.0098])\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.7407 Acc: 0.6818\n",
      "weights\n",
      "tensor([-0.0187,  0.0260, -0.0134,  ..., -0.0109,  0.0002,  0.0084])\n",
      "val Loss: 0.6636 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0187,  0.0260, -0.0134,  ..., -0.0109,  0.0002,  0.0084])\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.9375 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0187,  0.0276, -0.0106,  ..., -0.0113,  0.0020,  0.0082])\n",
      "val Loss: 0.9196 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0187,  0.0276, -0.0106,  ..., -0.0113,  0.0020,  0.0082])\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.9664 Acc: 0.6515\n",
      "weights\n",
      "tensor([-0.0188,  0.0305, -0.0092,  ..., -0.0121,  0.0027,  0.0086])\n",
      "val Loss: 1.2458 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0188,  0.0305, -0.0092,  ..., -0.0121,  0.0027,  0.0086])\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.0069 Acc: 0.6970\n",
      "weights\n",
      "tensor([-0.0190,  0.0315, -0.0088,  ..., -0.0131,  0.0034,  0.0088])\n",
      "val Loss: 1.6938 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0190,  0.0315, -0.0088,  ..., -0.0131,  0.0034,  0.0088])\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.8838 Acc: 0.6818\n",
      "weights\n",
      "tensor([-0.0206,  0.0305, -0.0101,  ..., -0.0150,  0.0019,  0.0074])\n",
      "val Loss: 0.8420 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0206,  0.0305, -0.0101,  ..., -0.0150,  0.0019,  0.0074])\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.7065 Acc: 0.7273\n",
      "weights\n",
      "tensor([-0.0203,  0.0340, -0.0072,  ..., -0.0150,  0.0030,  0.0083])\n",
      "val Loss: 1.4425 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0203,  0.0340, -0.0072,  ..., -0.0150,  0.0030,  0.0083])\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1189 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0235,  0.0309, -0.0090,  ..., -0.0172, -0.0007,  0.0058])\n",
      "val Loss: 1.7068 Acc: 0.2941\n",
      "weights\n",
      "tensor([-0.0235,  0.0309, -0.0090,  ..., -0.0172, -0.0007,  0.0058])\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.7576\n",
      "weights\n",
      "tensor([-0.0206,  0.0369, -0.0029,  ..., -0.0154,  0.0028,  0.0086])\n",
      "val Loss: 1.6845 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0206,  0.0369, -0.0029,  ..., -0.0154,  0.0028,  0.0086])\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.6818\n",
      "weights\n",
      "tensor([-0.0223,  0.0370, -0.0024,  ..., -0.0162,  0.0019,  0.0079])\n",
      "val Loss: 1.5832 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0223,  0.0370, -0.0024,  ..., -0.0162,  0.0019,  0.0079])\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.0365 Acc: 0.6364\n",
      "weights\n",
      "tensor([-0.0236,  0.0360, -0.0017,  ..., -0.0177,  0.0020,  0.0080])\n",
      "val Loss: 0.8307 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0236,  0.0360, -0.0017,  ..., -0.0177,  0.0020,  0.0080])\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.8449 Acc: 0.6212\n",
      "weights\n",
      "tensor([-0.0246,  0.0380, -0.0001,  ..., -0.0193,  0.0024,  0.0076])\n",
      "val Loss: 0.8223 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0246,  0.0380, -0.0001,  ..., -0.0193,  0.0024,  0.0076])\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.9625 Acc: 0.6212\n",
      "weights\n",
      "tensor([-0.0262,  0.0390,  0.0011,  ..., -0.0203,  0.0031,  0.0077])\n",
      "val Loss: 0.7664 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0262,  0.0390,  0.0011,  ..., -0.0203,  0.0031,  0.0077])\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.7261 Acc: 0.6667\n",
      "weights\n",
      "tensor([-0.0277,  0.0395,  0.0021,  ..., -0.0215,  0.0032,  0.0062])\n",
      "val Loss: 1.0365 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0277,  0.0395,  0.0021,  ..., -0.0215,  0.0032,  0.0062])\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.4767 Acc: 0.6818\n",
      "weights\n",
      "tensor([-0.0302,  0.0382,  0.0015,  ..., -0.0232,  0.0015,  0.0039])\n",
      "val Loss: 1.0276 Acc: 0.4118\n",
      "weights\n",
      "tensor([-0.0302,  0.0382,  0.0015,  ..., -0.0232,  0.0015,  0.0039])\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.7336 Acc: 0.7424\n",
      "weights\n",
      "tensor([-0.0301,  0.0418,  0.0040,  ..., -0.0220,  0.0016,  0.0048])\n",
      "val Loss: 0.8186 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0301,  0.0418,  0.0040,  ..., -0.0220,  0.0016,  0.0048])\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.2256 Acc: 0.6515\n",
      "weights\n",
      "tensor([-0.0297,  0.0449,  0.0061,  ..., -0.0231,  0.0037,  0.0052])\n",
      "val Loss: 1.4575 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0297,  0.0449,  0.0061,  ..., -0.0231,  0.0037,  0.0052])\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.6706 Acc: 0.7576\n",
      "weights\n",
      "tensor([-0.0309,  0.0452,  0.0067,  ..., -0.0243,  0.0036,  0.0046])\n",
      "val Loss: 1.3636 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0309,  0.0452,  0.0067,  ..., -0.0243,  0.0036,  0.0046])\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.6193 Acc: 0.6970\n",
      "weights\n",
      "tensor([-0.0322,  0.0443,  0.0059,  ..., -0.0258,  0.0024,  0.0029])\n",
      "val Loss: 1.0013 Acc: 0.4118\n",
      "weights\n",
      "tensor([-0.0322,  0.0443,  0.0059,  ..., -0.0258,  0.0024,  0.0029])\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.7727\n",
      "weights\n",
      "tensor([-0.0307,  0.0475,  0.0094,  ..., -0.0255,  0.0047,  0.0041])\n",
      "val Loss: 1.4969 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0307,  0.0475,  0.0094,  ..., -0.0255,  0.0047,  0.0041])\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0327,  0.0455,  0.0095,  ..., -0.0283,  0.0031,  0.0022])\n",
      "val Loss: 1.0295 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0327,  0.0455,  0.0095,  ..., -0.0283,  0.0031,  0.0022])\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.9430 Acc: 0.5758\n",
      "weights\n",
      "tensor([-0.0302,  0.0503,  0.0148,  ..., -0.0261,  0.0069,  0.0044])\n",
      "val Loss: 2.8948 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0302,  0.0503,  0.0148,  ..., -0.0261,  0.0069,  0.0044])\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.7692 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0352,  0.0456,  0.0099,  ..., -0.0307,  0.0011,  0.0005])\n",
      "val Loss: 1.2734 Acc: 0.3529\n",
      "weights\n",
      "tensor([-0.0352,  0.0456,  0.0099,  ..., -0.0307,  0.0011,  0.0005])\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.9966 Acc: 0.6515\n",
      "weights\n",
      "tensor([-0.0318,  0.0513,  0.0162,  ..., -0.0283,  0.0058,  0.0041])\n",
      "val Loss: 2.2048 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0318,  0.0513,  0.0162,  ..., -0.0283,  0.0058,  0.0041])\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.7566 Acc: 0.6667\n",
      "weights\n",
      "tensor([-0.0343,  0.0509,  0.0156,  ..., -0.0291,  0.0044,  0.0027])\n",
      "val Loss: 1.6243 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0343,  0.0509,  0.0156,  ..., -0.0291,  0.0044,  0.0027])\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.8686 Acc: 0.6970\n",
      "weights\n",
      "tensor([-0.0340,  0.0517,  0.0160,  ..., -0.0293,  0.0037,  0.0028])\n",
      "val Loss: 1.8819 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0340,  0.0517,  0.0160,  ..., -0.0293,  0.0037,  0.0028])\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.8395 Acc: 0.6818\n",
      "weights\n",
      "tensor([-0.0362,  0.0502,  0.0157,  ..., -0.0312,  0.0020,  0.0017])\n",
      "val Loss: 1.1242 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0362,  0.0502,  0.0157,  ..., -0.0312,  0.0020,  0.0017])\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.7305 Acc: 0.6970\n",
      "weights\n",
      "tensor([-0.0354,  0.0538,  0.0199,  ..., -0.0294,  0.0052,  0.0026])\n",
      "val Loss: 2.5293 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0354,  0.0538,  0.0199,  ..., -0.0294,  0.0052,  0.0026])\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.8030\n",
      "weights\n",
      "tensor([-3.7951e-02,  5.1375e-02,  1.9404e-02,  ..., -3.2019e-02,\n",
      "         3.8419e-03,  7.0558e-05])\n",
      "val Loss: 0.9338 Acc: 0.6471\n",
      "weights\n",
      "tensor([-3.7951e-02,  5.1375e-02,  1.9404e-02,  ..., -3.2019e-02,\n",
      "         3.8419e-03,  7.0558e-05])\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.6802 Acc: 0.7424\n",
      "weights\n",
      "tensor([-0.0398,  0.0514,  0.0201,  ..., -0.0332,  0.0038, -0.0013])\n",
      "val Loss: 1.1196 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0398,  0.0514,  0.0201,  ..., -0.0332,  0.0038, -0.0013])\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.7727\n",
      "weights\n",
      "tensor([-0.0395,  0.0516,  0.0209,  ..., -0.0340,  0.0039, -0.0017])\n",
      "val Loss: 0.9164 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0395,  0.0516,  0.0209,  ..., -0.0340,  0.0039, -0.0017])\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.4538 Acc: 0.8333\n",
      "weights\n",
      "tensor([-0.0393,  0.0527,  0.0223,  ..., -0.0343,  0.0046, -0.0018])\n",
      "val Loss: 1.7294 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0393,  0.0527,  0.0223,  ..., -0.0343,  0.0046, -0.0018])\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.4346 Acc: 0.8636\n",
      "weights\n",
      "tensor([-0.0395,  0.0529,  0.0233,  ..., -0.0350,  0.0050, -0.0020])\n",
      "val Loss: 1.3383 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0395,  0.0529,  0.0233,  ..., -0.0350,  0.0050, -0.0020])\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.7098 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0406,  0.0522,  0.0242,  ..., -0.0360,  0.0054, -0.0025])\n",
      "val Loss: 1.2316 Acc: 0.5882\n",
      "weights\n",
      "tensor([-0.0406,  0.0522,  0.0242,  ..., -0.0360,  0.0054, -0.0025])\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.6694 Acc: 0.6667\n",
      "weights\n",
      "tensor([-0.0410,  0.0545,  0.0262,  ..., -0.0354,  0.0064, -0.0020])\n",
      "val Loss: 1.4050 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0410,  0.0545,  0.0262,  ..., -0.0354,  0.0064, -0.0020])\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.7724 Acc: 0.7727\n",
      "weights\n",
      "tensor([-0.0446,  0.0507,  0.0241,  ..., -0.0387,  0.0041, -0.0042])\n",
      "val Loss: 2.3494 Acc: 0.2353\n",
      "weights\n",
      "tensor([-0.0446,  0.0507,  0.0241,  ..., -0.0387,  0.0041, -0.0042])\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.3866 Acc: 0.6667\n",
      "weights\n",
      "tensor([-0.0405,  0.0586,  0.0326,  ..., -0.0342,  0.0101,  0.0002])\n",
      "val Loss: 3.2009 Acc: 0.7059\n",
      "weights\n",
      "tensor([-0.0405,  0.0586,  0.0326,  ..., -0.0342,  0.0101,  0.0002])\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.7424\n",
      "weights\n",
      "tensor([-0.0428,  0.0570,  0.0323,  ..., -0.0369,  0.0082, -0.0016])\n",
      "val Loss: 2.0667 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0428,  0.0570,  0.0323,  ..., -0.0369,  0.0082, -0.0016])\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 0.7576\n",
      "weights\n",
      "tensor([-0.0440,  0.0556,  0.0325,  ..., -0.0395,  0.0072, -0.0026])\n",
      "val Loss: 1.5064 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0440,  0.0556,  0.0325,  ..., -0.0395,  0.0072, -0.0026])\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.4475 Acc: 0.7727\n",
      "weights\n",
      "tensor([-0.0455,  0.0559,  0.0331,  ..., -0.0401,  0.0064, -0.0033])\n",
      "val Loss: 1.1810 Acc: 0.5882\n",
      "weights\n",
      "tensor([-0.0455,  0.0559,  0.0331,  ..., -0.0401,  0.0064, -0.0033])\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.7956 Acc: 0.7121\n",
      "weights\n",
      "tensor([-0.0455,  0.0572,  0.0352,  ..., -0.0403,  0.0065, -0.0035])\n",
      "val Loss: 1.5773 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0455,  0.0572,  0.0352,  ..., -0.0403,  0.0065, -0.0035])\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.4326 Acc: 0.7576\n",
      "weights\n",
      "tensor([-0.0458,  0.0584,  0.0361,  ..., -0.0410,  0.0073, -0.0040])\n",
      "val Loss: 1.5880 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0458,  0.0584,  0.0361,  ..., -0.0410,  0.0073, -0.0040])\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.4549 Acc: 0.7879\n",
      "weights\n",
      "tensor([-0.0459,  0.0598,  0.0370,  ..., -0.0414,  0.0074, -0.0038])\n",
      "val Loss: 1.8228 Acc: 0.6471\n",
      "weights\n",
      "tensor([-0.0459,  0.0598,  0.0370,  ..., -0.0414,  0.0074, -0.0038])\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.4329 Acc: 0.8182\n",
      "weights\n",
      "tensor([-0.0474,  0.0592,  0.0364,  ..., -0.0426,  0.0057, -0.0052])\n",
      "val Loss: 1.2680 Acc: 0.5882\n",
      "weights\n",
      "tensor([-0.0474,  0.0592,  0.0364,  ..., -0.0426,  0.0057, -0.0052])\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.5515 Acc: 0.7424\n",
      "weights\n",
      "tensor([-0.0487,  0.0589,  0.0377,  ..., -0.0443,  0.0056, -0.0062])\n",
      "val Loss: 1.4133 Acc: 0.5294\n",
      "weights\n",
      "tensor([-0.0487,  0.0589,  0.0377,  ..., -0.0443,  0.0056, -0.0062])\n",
      "\n",
      "Training complete in 161m 55s\n",
      "Best val Acc: 0.705882\n"
     ]
    }
   ],
   "source": [
    "model, val_acc_history, val_loss_history, time_elapsed, labels_lst, preds_lst, weights = train_model(model,\n",
    "                                     dataloaders = dataloaders_dict, \n",
    "                                     criterion = torch.nn.CrossEntropyLoss(),\n",
    "                                     optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "                                     num_epochs=50)\n",
    "#optimizer = torch.optim.Adam,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c31e6b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5050362968878985,\n",
       " 0.6728084508110496,\n",
       " 0.6971796610776115,\n",
       " 1.881883674465558,\n",
       " 1.1812916196444456,\n",
       " 1.5440019884785323,\n",
       " 0.6636449725312346,\n",
       " 0.9195905088940087,\n",
       " 1.2457574425703462,\n",
       " 1.6937685438189125,\n",
       " 0.8420120554373545,\n",
       " 1.442481076474959,\n",
       " 1.7067869007587433,\n",
       " 1.6844997112630689,\n",
       " 1.5831641084993915,\n",
       " 0.8306915802771554,\n",
       " 0.8223116935833412,\n",
       " 0.7663666313404546,\n",
       " 1.0365187055705225,\n",
       " 1.0276007433147991,\n",
       " 0.818581648170948,\n",
       " 1.4575308415223844,\n",
       " 1.3635745785380577,\n",
       " 1.001259610933416,\n",
       " 1.4968719283745433,\n",
       " 1.0295357582542826,\n",
       " 2.8948114066697266,\n",
       " 1.2733678668737411,\n",
       " 2.204823799414311,\n",
       " 1.6243335346790606,\n",
       " 1.8819410593973505,\n",
       " 1.124245326637345,\n",
       " 2.5292590371770047,\n",
       " 0.9338270201731254,\n",
       " 1.1195662628366227,\n",
       " 0.9163765801007256,\n",
       " 1.729351720534717,\n",
       " 1.3382510571973398,\n",
       " 1.2315647352267713,\n",
       " 1.4050415633520221,\n",
       " 2.349367411040208,\n",
       " 3.200935031954386,\n",
       " 2.066686276495388,\n",
       " 1.5063999934645835,\n",
       " 1.1810385312282425,\n",
       " 1.577321155998267,\n",
       " 1.5879771693075515,\n",
       " 1.8227917153135957,\n",
       " 1.2680411514113932,\n",
       " 1.4133200890877669]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a123ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.5294, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.2941, dtype=torch.float64),\n",
       " tensor(0.2941, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.2941, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.4118, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.4118, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.3529, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.5882, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.2353, dtype=torch.float64),\n",
       " tensor(0.7059, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.5882, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.6471, dtype=torch.float64),\n",
       " tensor(0.5882, dtype=torch.float64),\n",
       " tensor(0.5294, dtype=torch.float64)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de31394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loss_acc = pd.DataFrame(history.history)\n",
    "df_loss= df_loss_acc[['loss','val_loss']]\n",
    "df_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\n",
    "df_acc= df_loss_acc[['binary_accuracy','val_binary_accuracy']]\n",
    "df_acc.rename(columns={'binary_accuracy':'train','val_binary_accuracy':'validation'},inplace=True)\n",
    "df_loss.plot(title='Model loss',figsize=(12,8)).set(xlabel='Epoch',ylabel='Loss')\n",
    "df_acc.plot(title='Model Accuracy',figsize=(12,8)).set(xlabel='Epoch',ylabel='Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "122bb0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 minutes, 25 seconds\n"
     ]
    }
   ],
   "source": [
    "print(str(int(time_elapsed // 60)) + \" minutes, \" + str(int(time_elapsed % 60)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d12d9b",
   "metadata": {},
   "source": [
    "False Positive: A non-responder who is predicted to be a responder\n",
    "\n",
    "False Negative: A responder who is predicted to be a non-responder\n",
    "\n",
    "True Positive: A responder who is predicted to be a responder\n",
    "\n",
    "True Negative: A non-responder who is predicted to be a non-responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc6461c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate: 0.13253012048192772\n",
      "False negative rate: 0.1686746987951807\n",
      "True positive rate: 0.08433734939759036\n",
      "True negative rate: 0.6144578313253012\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for i in range(len(labels_lst)):\n",
    "    if labels_lst[i] == 0 and preds_lst[i] == 1:\n",
    "        fp += 1\n",
    "    if labels_lst[i] == 1 and preds_lst[i] == 0:\n",
    "        fn += 1\n",
    "    if labels_lst[i] == 1 and preds_lst[i] == 1:\n",
    "        tp += 1\n",
    "    if labels_lst[i] == 0 and preds_lst[i] == 0:\n",
    "        tn += 1\n",
    "    \n",
    "fp = fp / len(labels_lst)\n",
    "fn = fn / len(labels_lst)\n",
    "tp = tp / len(labels_lst)\n",
    "tn = tn / len(labels_lst)\n",
    "\n",
    "print(\"False positive rate: \" + str(fp))\n",
    "print(\"False negative rate: \" + str(fn))\n",
    "print(\"True positive rate: \" + str(tp))\n",
    "print(\"True negative rate: \" + str(tn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
